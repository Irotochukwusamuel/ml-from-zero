{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3778b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160. 220. 336. 360. 410. 430.]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest for Regression\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Feature 0 → Size\n",
    "Feature 1 → Rooms\n",
    "Feature 2 → Age\n",
    "\"\"\"\n",
    "X_class = np.array(\n",
    "    [\n",
    "        [50, 1, 30],\n",
    "        [70, 2, 20], \n",
    "        [100, 3, 10], \n",
    "        [120, 3, 5], \n",
    "        [140, 4, 2], \n",
    "        [160, 5, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "Y_class = np.array([150, 200, 300, 360, 400, 450])  # Target → Price\n",
    "\n",
    "\n",
    "def calc_threshold(x):\n",
    "    uni = np.unique(x)\n",
    "    return (uni[1:] + uni[:-1]) / 2\n",
    "\n",
    "\n",
    "def random_feature_selection(X):\n",
    "    n = X.shape[1]\n",
    "    indices = np.random.choice(n, int(np.sqrt(n)), replace=False)\n",
    "    return X[:, indices]\n",
    "\n",
    "\n",
    "def weighted_variance(left_side, right_side):\n",
    "    num_of_samples = len(left_side) + len(right_side)\n",
    "    left_variance = (len(left_side) / num_of_samples) * np.var(left_side)\n",
    "    right_variance = (len(right_side) / num_of_samples) * np.var(right_side)\n",
    "    return left_variance + right_variance\n",
    "\n",
    "\n",
    "def regression_best_split(X, Y):\n",
    "    best_threshold = None\n",
    "    best_feature = None\n",
    "    best_variance = float(\"inf\")  # Start with infinity\n",
    "    _, num_of_features = X.shape\n",
    "    random_feature_selection = np.random.choice(\n",
    "        num_of_features, int(np.sqrt(num_of_features)), replace=False\n",
    "    )\n",
    "\n",
    "    for feature_idx in random_feature_selection:\n",
    "        feature = X[:, feature_idx]\n",
    "        thresholds = calc_threshold(feature)\n",
    "        for threshold in thresholds:\n",
    "            left_side = Y[feature < threshold]\n",
    "            right_side = Y[feature >= threshold]\n",
    "\n",
    "            if len(left_side) == 0 or len(right_side) == 0:\n",
    "                continue\n",
    "\n",
    "            var_split = weighted_variance(left_side, right_side)\n",
    "\n",
    "            if var_split < best_variance:\n",
    "                best_feature = feature_idx\n",
    "                best_variance = var_split\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "\n",
    "def make_regression_leaf(Y):\n",
    "    return {\"type\": \"leaf\", \"prediction\": np.mean(Y)}\n",
    "\n",
    "\n",
    "def regression_build_tree(X, Y, depth=0, max_depth=3, min_samples=2):\n",
    "    if len(np.unique(Y)) == 1 or depth >= max_depth or len(Y) < min_samples:\n",
    "        return make_regression_leaf(Y)\n",
    "\n",
    "    feature, threshold = regression_best_split(X, Y)\n",
    "\n",
    "    if feature is None:\n",
    "        return make_regression_leaf(Y)\n",
    "\n",
    "    left_mask = X[:, feature] < threshold\n",
    "    right_mask = ~left_mask\n",
    "\n",
    "    left_child = regression_build_tree(X[left_mask], Y[left_mask], depth=depth + 1)\n",
    "    right_child = regression_build_tree(X[right_mask], Y[right_mask], depth=depth + 1)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"node\",\n",
    "        \"feature\": feature,\n",
    "        \"threshold\": threshold,\n",
    "        \"left\": left_child,\n",
    "        \"right\": right_child,\n",
    "    }\n",
    "\n",
    "\n",
    "def bootstrap_sample(X, Y):\n",
    "    n = len(X)\n",
    "    indices = np.random.choice(n, n, replace=True)\n",
    "    return X[indices], Y[indices]\n",
    "\n",
    "\n",
    "def build_forest(X, Y, n_trees=3):\n",
    "    forest = []\n",
    "    for _ in range(n_trees):\n",
    "        X_b, Y_b = bootstrap_sample(X, Y)\n",
    "        tree = regression_build_tree(X_b, Y_b)\n",
    "        forest.append(tree)\n",
    "    return forest\n",
    "\n",
    "\n",
    "def reg_predict_one(x, tree):\n",
    "    if tree[\"type\"] == \"leaf\":\n",
    "        return tree[\"prediction\"]\n",
    "\n",
    "    feature = tree[\"feature\"]\n",
    "    threshold = tree[\"threshold\"]\n",
    "\n",
    "    if x[feature] < threshold:\n",
    "        return reg_predict_one(x, tree[\"left\"])\n",
    "    else:\n",
    "        return reg_predict_one(x, tree[\"right\"])\n",
    "\n",
    "\n",
    "def reg_predict(x, tree):\n",
    "    return [reg_predict_one(i, tree) for i in x]\n",
    "\n",
    "\n",
    "def forest_predict(X, forest):\n",
    "    predictions = np.array([reg_predict(X, tree) for tree in forest])\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "\n",
    "forest = build_forest(X_class, Y_class, n_trees=5)\n",
    "predictions = forest_predict(X_class, forest)\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
