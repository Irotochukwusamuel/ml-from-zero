{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc063d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'node', 'feature': 1, 'threshold': 0.25, 'left': {'type': 'leaf', 'prediction': 0}, 'right': {'type': 'leaf', 'prediction': 1}}\n",
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree for Classification\n",
    "import numpy as np\n",
    "\n",
    "X_class = np.array(\n",
    "    [\n",
    "        [5, 1, 1, 0, 1],  # Hours, Attendance, Sleep, PhoneUsage, Tutoring\n",
    "        [2, 0, 0, 1, 0],\n",
    "        [6, 1, 1, 0.5, 0],\n",
    "        [1, 0, 0, 1, 0],\n",
    "        [4, 0.5, 1, 0, 1],\n",
    "        [10, 0, 0, 0, 0],\n",
    "    ]\n",
    ")\n",
    "y_class = np.array([1, 0, 1, 0, 1, 0])  # 1 = Passed, 0 = Failed\n",
    "\n",
    "\n",
    "def calc_thresholds(x):\n",
    "    return set((x[1:] + x[:-1]) / 2)\n",
    "\n",
    "\n",
    "def class_count(data):\n",
    "    classes = {x: np.count_nonzero(data == x) for x in set(data)}\n",
    "    return {str(x): (y / len(data)) for x, y in classes.items()}\n",
    "\n",
    "\n",
    "def calc_gini(data):\n",
    "    return 1 - (sum(x**2 for x in class_count(data).values()))\n",
    "\n",
    "\n",
    "def best_split(X, Y):\n",
    "    features = X[:].T \n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    best_gini = 1.0  # start with worst impurity\n",
    "    merged_x_y = np.hstack((X, Y.reshape(-1, 1)))  # merge the X & Y\n",
    "\n",
    "    for feature_idx, feature in enumerate(features):\n",
    "        thresholds = calc_thresholds(np.sort(feature))\n",
    "        for threshold in thresholds:\n",
    "            split = {\n",
    "                \"left\": np.array(\n",
    "                    [x[-1] for x in merged_x_y if x[feature_idx] < threshold]\n",
    "                ),  # left split 1 - sum of Pk^2\n",
    "                \"right\": np.array(\n",
    "                    [x[-1] for x in merged_x_y if x[feature_idx] >= threshold]\n",
    "                ),  # right split 1 - sum of Pk^2\n",
    "            }\n",
    "\n",
    "            ginis = np.array([calc_gini(split[\"left\"]), calc_gini(split[\"right\"])])\n",
    "\n",
    "            l = np.array([len(x) for x in split.values()])\n",
    "\n",
    "            # Sum of P(True||False) *  left & right split 1 - sum of Pk^2\n",
    "            gini_split = np.sum((l / sum(l)) * ginis)\n",
    "\n",
    "            if gini_split < best_gini:\n",
    "                best_gini = gini_split\n",
    "                best_threshold = threshold\n",
    "                best_feature = feature_idx\n",
    "\n",
    "    return best_threshold, best_feature\n",
    "\n",
    "def make_leaf(y):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    return {\"type\": \"leaf\", \"prediction\": values[np.argmax(counts)]}\n",
    "\n",
    "def build_tree(X, Y, depth=0, max_depth=3, min_samples=2):\n",
    "    if len(np.unique(Y)) == 1:\n",
    "        return make_leaf(Y)\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        return make_leaf(Y)\n",
    "\n",
    "    if len(Y) < min_samples:\n",
    "        return make_leaf(Y)\n",
    "    \n",
    "\n",
    "    threshold, feature = best_split(X, Y)\n",
    "\n",
    "    if feature is None:  \n",
    "        return make_leaf(Y)\n",
    "    \n",
    "    left_mask = X[:, feature] < threshold\n",
    "    right_mask = ~left_mask\n",
    "\n",
    "\n",
    "    left_child = build_tree(\n",
    "        X[left_mask],\n",
    "        Y[left_mask],\n",
    "        depth=depth + 1,\n",
    "        max_depth=max_depth,\n",
    "        min_samples=min_samples\n",
    "    )\n",
    "\n",
    "    right_child = build_tree(\n",
    "        X[right_mask],\n",
    "        Y[right_mask],\n",
    "        depth=depth + 1,\n",
    "        max_depth=max_depth,\n",
    "        min_samples=min_samples,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"type\": \"node\",\n",
    "        \"feature\": feature,\n",
    "        \"threshold\": threshold,\n",
    "        \"left\": left_child,\n",
    "        \"right\": right_child,\n",
    "    }\n",
    "\n",
    "\n",
    "def predict_one(x, tree):\n",
    "    if tree['type'] == 'leaf':\n",
    "        return tree['prediction']\n",
    "\n",
    "    feature = tree[\"feature\"]\n",
    "    threshold = tree['threshold']\n",
    "    if x[feature] < threshold:\n",
    "        return predict_one(x, tree['left'])\n",
    "    else:\n",
    "        return predict_one(x, tree['right'])\n",
    "\n",
    "def predict(x, tree):\n",
    "    return np.array([predict_one(i, tree) for i in x])\n",
    "\n",
    "tree = build_tree(X_class, y_class)\n",
    "print(tree)\n",
    "X_new = np.array(\n",
    "    [\n",
    "        [1, 0, 0, 1, 0],\n",
    "        [6, 1, 1, 0, 1],\n",
    "        [3, 0.5, 1, 0, 0],\n",
    "    ]\n",
    ")\n",
    "print(predict(X_new, tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1783b949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree for Regression\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(\n",
    "    [[50, 1, 30], [70, 2, 20], [100, 3, 10], [120, 3, 5], [140, 4, 2], [160, 5, 1]]\n",
    ")\n",
    "Y = np.array([150, 200, 300, 360, 400, 450])\n",
    "\n",
    "variance = np.var(Y)\n",
    "\n",
    "\n",
    "def calc_threshold(x):\n",
    "    uni = np.unique(x)\n",
    "    return (uni[1:] + uni[:-1]) / 2\n",
    "\n",
    "\n",
    "def regression_best_split(X, Y):\n",
    "    best_threshold = None\n",
    "    best_feature = None\n",
    "    best_variance = float(\"inf\")  # Start with infinity\n",
    "    num_of_samples, num_of_features = X.shape\n",
    "\n",
    "    for feature_idx in np.arange(num_of_features):\n",
    "        feature = X[:, feature_idx]\n",
    "        thresholds = calc_threshold(feature)\n",
    "        for threshold in thresholds:\n",
    "            left_side = Y[feature < threshold]\n",
    "            right_side = Y[feature >= threshold]\n",
    "\n",
    "            if len(left_side) == 0 or len(right_side) == 0:\n",
    "                continue\n",
    "\n",
    "            left_variance = (len(left_side) / num_of_samples) * np.var(left_side)\n",
    "            right_variance = (len(right_side) / num_of_samples) * np.var(right_side)\n",
    "            var_split = left_variance + right_variance\n",
    "\n",
    "            if var_split < best_variance:\n",
    "                best_feature = feature_idx\n",
    "                best_variance = var_split\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "\n",
    "def make_regression_leaf(Y):\n",
    "    return {\"type\": \"leaf\", \"prediction\": np.mean(Y)}\n",
    "\n",
    "\n",
    "def regression_build_tree(X, Y, depth=0, max_depth=3, min_samples=2):\n",
    "    if len(np.unique(Y)) == 1 or depth >= max_depth or len(Y) < min_samples:\n",
    "        return make_regression_leaf(Y)\n",
    "\n",
    "    feature, threshold = regression_best_split(X, Y)\n",
    "\n",
    "    if feature is None:\n",
    "        return make_regression_leaf(Y)\n",
    "\n",
    "    left_mask = X[:, feature] < threshold\n",
    "    right_mask = ~left_mask\n",
    "\n",
    "    left_child = regression_build_tree(X[left_mask], Y[left_mask], depth=depth + 1)\n",
    "    right_child = regression_build_tree(X[right_mask], Y[right_mask], depth=depth + 1)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"node\",\n",
    "        \"feature\": feature,\n",
    "        \"threshold\": threshold,\n",
    "        \"left\": left_child,\n",
    "        \"right\": right_child,\n",
    "    }\n",
    "\n",
    "\n",
    "def reg_predict_one(x, tree):\n",
    "    if tree['type'] == \"leaf\":\n",
    "        return tree[\"prediction\"]\n",
    "\n",
    "    feature = tree[\"feature\"]\n",
    "    threshold = tree[\"threshold\"]\n",
    "\n",
    "    if x[feature] < threshold:\n",
    "        return reg_predict_one(x, tree[\"left\"])\n",
    "    else:\n",
    "        return reg_predict_one(x, tree[\"right\"])\n",
    "\n",
    "def reg_predict(x, tree):\n",
    "    return [reg_predict_one(i, tree) for i in x]\n",
    "\n",
    "\n",
    "reg_tree = regression_build_tree(X,Y)\n",
    "new_sample = np.array([80, 2, 15])\n",
    "prediction = reg_predict_one(new_sample, reg_tree)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f2d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Tree - MSE: 0.8134723319046022, R2: 0.9597017750640147\n",
      "Sklearn Tree - MSE: 0.8134723319046019, R2: 0.9597017750640147\n"
     ]
    }
   ],
   "source": [
    "# compare the custom regression tree to SKlearn regresion tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "X_large = np.sort(5 * np.random.rand(100, 1), axis=0)\n",
    "Y_large = 3 * X_large.flatten() + np.random.normal(0, 1, 100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_large, Y_large, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "sk_tree = DecisionTreeRegressor(\n",
    "    max_depth=3, min_samples_split=2, criterion=\"squared_error\"\n",
    ")\n",
    "\n",
    "# My custom regression tree\n",
    "reg_tree = regression_build_tree(X_train, y_train)\n",
    "\n",
    "# sklearn fit\n",
    "sk_tree.fit(X_train, y_train)\n",
    "\n",
    "# my custom regression prediction\n",
    "custom_preds = reg_predict(X_test, reg_tree)\n",
    "\n",
    "# sklearn prediction\n",
    "sk_preds = sk_tree.predict(X_test)\n",
    "\n",
    "# MSE for my custom regression\n",
    "mse_custom = mean_squared_error(y_test, custom_preds)\n",
    "\n",
    "# MSE for SKlearn\n",
    "mse_sk = mean_squared_error(y_test, sk_preds)\n",
    "\n",
    "# R2 for my custom regression\n",
    "r2_custom = r2_score(y_test, custom_preds)\n",
    "\n",
    "# R2 for sklearn\n",
    "r2_sk = r2_score(y_test, sk_preds)\n",
    "\n",
    "print(f\"Custom Tree - MSE: {mse_custom}, R2: {r2_custom}\")\n",
    "print(f\"Sklearn Tree - MSE: {mse_sk}, R2: {r2_sk}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
