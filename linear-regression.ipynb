{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8304b984",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T12:41:21.324517Z",
     "start_time": "2025-12-22T12:41:21.321049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.74402748e-11]\n",
      " [ 5.00000000e+00]\n",
      " [-5.00000000e+01]]\n",
      "[350.]\n"
     ]
    }
   ],
   "source": [
    "# Normal Equation for Multiple Linear Regression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 50, 2], [1, 70, 3], [1, 100, 4]])\n",
    "y = np.array([[150], [200], [300]])\n",
    "new_house = np.array([1, 90, 2])  # include 1 for intercept\n",
    "\n",
    "\n",
    "def multiple_linear_regression(x, y, new_pred):\n",
    "    x_transpose = x.transpose()\n",
    "    x_transpose_x = np.matmul(x_transpose, x)\n",
    "\n",
    "    x_transpose_y = np.matmul(x_transpose, y)\n",
    "    inverse_x_transpose_x = np.linalg.inv(x_transpose_x)\n",
    "    weight = np.matmul(inverse_x_transpose_x, x_transpose_y)\n",
    "\n",
    "    print(weight)\n",
    "\n",
    "    predicted_price = np.matmul(new_pred, weight)\n",
    "    return predicted_price\n",
    "\n",
    "print(multiple_linear_regression(x, y, new_house))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "394fc2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.5\n"
     ]
    }
   ],
   "source": [
    "# Normal Equation for Simple Linear Regression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "graph = np.array([\n",
    "    [1,50],\n",
    "    [2, 55],\n",
    "    [3, 65],\n",
    "    [4, 70],\n",
    "    [5, 80]\n",
    "])\n",
    "\n",
    "\n",
    "n = len(graph)\n",
    "x_y = [np.prod(x) for x in graph]\n",
    "x_2 = [np.square(x[0]) for x in graph]\n",
    "x_sum = sum([x[0] for x in graph])\n",
    "y_sum = sum([x[1] for x in graph])\n",
    "\n",
    "m_numerator = (n * (sum(x_y))) - (x_sum * y_sum) \n",
    "m_denomerator = (n * sum(x_2)) - (np.square(x_sum))\n",
    "m = m_numerator/m_denomerator\n",
    "\n",
    "b = ((y_sum) - (m * x_sum))/n\n",
    "\n",
    "y_pred = (m * 2) + b\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb9e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00572884]\n",
      " [0.03666301]\n",
      " [0.07370063]\n",
      " [0.08590752]]\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression using Gradient Descent\n",
    "import numpy as np\n",
    "\n",
    "dataset = np.array(\n",
    "    [\n",
    "        [ 50, 1],\n",
    "        [ 70, 2],\n",
    "        [ 100, 3],\n",
    "        [ 120, 3],\n",
    "    ]\n",
    ")\n",
    "y = np.array([\n",
    "    [150],[200],[300],[360]\n",
    "])\n",
    "\n",
    "learning_rate = 0.0001\n",
    "iteration = 1\n",
    "tolerance = 1e-6  # minimum change in loss\n",
    "scale=True\n",
    "mean = np.mean(dataset, axis=0)\n",
    "standard_deviation = np.std(dataset, axis=0)\n",
    "\n",
    "def Linear_regression_gradient_descent(dataset, y, learning_rate, iteration, scale, tolerance):\n",
    "    \n",
    "    if scale:\n",
    "        dataset = (dataset - mean)/standard_deviation\n",
    "\n",
    "    # adding bias to the features\n",
    "    X = np.hstack((np.ones((dataset.shape[0], 1)), dataset))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "\n",
    "    #initializing weights\n",
    "    w = np.zeros((X.shape[1], 1))\n",
    "\n",
    "    for i in range(iteration):\n",
    "        predictions = X @ w\n",
    "        error = predictions - y\n",
    "        loss = np.mean(error ** 2)\n",
    "        if abs(prev_loss - loss) < tolerance:\n",
    "            print(\n",
    "                f\"Stopping at iteration {i + 1}, loss change < {tolerance} : {abs(prev_loss - loss)}\"\n",
    "            )\n",
    "            break\n",
    "        gradient = np.multiply((2/dataset.shape[0]),(X.T @ error))\n",
    "        w = w - (learning_rate * gradient)\n",
    "        prev_loss = loss\n",
    "\n",
    "    return w\n",
    "\n",
    "def predict(weights, dataset):\n",
    "    new_scaled = (dataset - mean) / standard_deviation\n",
    "    X = np.hstack((np.ones((new_scaled.shape[0], 1)), new_scaled))\n",
    "    return X @ weights\n",
    "\n",
    "trained_weights = Linear_regression_gradient_descent(\n",
    "    dataset, y, learning_rate, iteration, scale, tolerance\n",
    ")\n",
    "print(predict(trained_weights, dataset))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
